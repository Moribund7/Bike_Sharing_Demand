{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Bike Sharing Demand</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <div align='right'>Filip Kowalski</right>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import  StandardScaler\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set figure size\n",
    "plt.rcParams['figure.figsize'] = (10,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename='train.csv'\n",
    "dataset=read_csv(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looking on data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time=pd.to_datetime(dataset.datetime)\n",
    "dataset.datetime=time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Fields\n",
    "<br>\n",
    "**datetime** - hourly date + timestamp  \n",
    "**season** -  1 = spring, 2 = summer, 3 = fall, 4 = winter \n",
    "<br>\n",
    "**holiday** - whether the day is considered a holidayr\n",
    "<br>\n",
    "**workingday** - whether the day is neither a weekend nor holiday\n",
    "<br>\n",
    "**weather**\n",
    "1. : Clear, Few clouds, Partly cloudy, Partly cloudy \n",
    "* : Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist \n",
    "* : Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds \n",
    "* : Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog \n",
    "\n",
    "\n",
    "\n",
    "**temp** - temperature in Celsius\n",
    "<br>\n",
    "**atemp** - \"feels like\" temperature in Celsius\n",
    "<br>\n",
    "**humidity** - relative humidity\n",
    "<br>\n",
    "**windspeed** - wind speed\n",
    "<br>\n",
    "**casual** - number of non-registered user rentals initiated\n",
    "<br>\n",
    "**registered** - number of registered user rentals initiated\n",
    "<br>\n",
    "**count** - number of total rentals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descriptions of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no null values. Data look corect (there is not strange values like negative values or to low or to hight numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = pd.cut(dataset['count'], [0, 100, 200,300,400,500,600,700,800,900])\n",
    "groups=dataset.groupby(bins)['count'].agg(['count', 'sum'])\n",
    "print(groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.plotting.scatter_matrix(dataset)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('precision',2)\n",
    "print(dataset.corr(method='pearson'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset['datetime'] = dataset['datetime'].dt.hour\n",
    "dataset=dataset.drop(columns=['registered','casual'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.plot(kind='density',subplots=True,layout=(4,4),sharex=False,sharey=False,legend=True,fontsize=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.plot(kind='box',subplots=True,layout=(4,4),sharex=False,sharey=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split-out validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array=dataset.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=array[:,:-1]\n",
    "Y=array[:,-1]\n",
    "validation_size=0.2\n",
    "seed=7\n",
    "X_train,X_validation,Y_train,Y_validation = train_test_split(X,Y,test_size=validation_size,random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test options and eveluation metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_folds=10\n",
    "scoring='neg_mean_squared_error'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spot-check algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models=[]\n",
    "models.append(('LR',LinearRegression()))\n",
    "models.append(('LASSO',Lasso()))\n",
    "models.append(('EN',ElasticNet()))\n",
    "models.append(('KNN',KNeighborsRegressor()))\n",
    "models.append(('CART',DecisionTreeRegressor()))\n",
    "models.append(('SVR',SVR()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results=[]\n",
    "names=[]\n",
    "for name, model in models:\n",
    "    kfold=KFold(n_splits=num_folds,random_state=seed,shuffle=True)\n",
    "    cv_results=cross_val_score(model,X_train,Y_train,cv=kfold,scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    message=\"%a: %f (%f)\" % (name,cv_results.mean(),cv_results.std())\n",
    "    print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure()\n",
    "fig.suptitle('Algorithm Comprasion')\n",
    "ax=fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=DecisionTreeRegressor()\n",
    "model.fit(X=X_train,y=Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=model.predict(X_validation)\n",
    "print(mean_squared_error(Y_validation,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This models dont look nice. We should standardize the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "piplines=[]\n",
    "piplines.append(('ScaledLR',Pipeline([('Scaler',StandardScaler()),('LR',LinearRegression())])))\n",
    "piplines.append(('ScaledLASSO',Pipeline([('Scaler',StandardScaler()),('LASSO',Lasso())])))\n",
    "piplines.append(('ScaledEN',Pipeline([('Scaler',StandardScaler()),('EN',ElasticNet())])))\n",
    "piplines.append(('ScaledKNN',Pipeline([('Scaler',StandardScaler()),('KNN',KNeighborsRegressor())])))\n",
    "piplines.append(('ScaledCART',Pipeline([('Scaler',StandardScaler()),('CART',DecisionTreeRegressor())])))\n",
    "piplines.append(('ScaledSVR',Pipeline([('Scaler',StandardScaler()),('SVR',SVR())])))\n",
    "\n",
    "results=[]\n",
    "names=[]\n",
    "for name, model in piplines:\n",
    "    kfold=KFold(n_splits=num_folds,random_state=seed,shuffle=True)\n",
    "    cv_results=cross_val_score(model,X_train,Y_train,cv=kfold,scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    message=\"%a: %f (%f)\" % (name,cv_results.mean(),cv_results.std())\n",
    "    print(message)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure()\n",
    "fig.suptitle('Algorithm Comprasion')\n",
    "ax=fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning ScaledCART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 10, stop = 4000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "splitter = ['best','random']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(2, 150, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10,3,7,15]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4,6,8,12]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {\n",
    "               'splitter': splitter,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               }\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CART = DecisionTreeRegressor()\n",
    "CART_random = RandomizedSearchCV(estimator = CART, param_distributions = random_grid, n_iter = 100, cv = 10, verbose=2, random_state=42, n_jobs = -1)\n",
    "\n",
    "CART_random.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CART_random.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best parameters for this model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models=[]\n",
    "models.append(('CART',DecisionTreeRegressor(splitter='best',min_samples_split=2,min_samples_leaf=8,max_depth=16)))\n",
    "results=[]\n",
    "names=[]\n",
    "for name, model in models:\n",
    "    kfold=KFold(n_splits=num_folds,random_state=seed,shuffle=True)\n",
    "    cv_results=cross_val_score(model,X_train,Y_train,cv=kfold,scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    message=\"%a: %f (%f)\" % (name,cv_results.mean(),cv_results.std())\n",
    "    print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=DecisionTreeRegressor(splitter='best',min_samples_split=7,min_samples_leaf=12,max_depth=90)\n",
    "results=[]\n",
    "model.fit(X=X_train,y=Y_train)\n",
    "predictions=model.predict(X_validation)\n",
    "print(mean_squared_error(Y_validation,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model get much bether result then with defult parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensembles=[]\n",
    "ensembles.append(('ScaledAB',Pipeline([('Scaler',StandardScaler()),('AB',AdaBoostRegressor())])))\n",
    "ensembles.append(('ScaledGBM',Pipeline([('Scaler',StandardScaler()),('GBM',GradientBoostingRegressor())])))\n",
    "ensembles.append(('ScaledRF',Pipeline([('Scaler',StandardScaler()),('RF',RandomForestRegressor())])))\n",
    "ensembles.append(('ScaledET',Pipeline([('Scaler',StandardScaler()),('ET',ExtraTreesRegressor())])))\n",
    "\n",
    "results=[]\n",
    "names=[]\n",
    "for name, model in ensembles:\n",
    "    kfold=KFold(n_splits=num_folds,random_state=seed,shuffle=True)\n",
    "    cv_results=cross_val_score(model,X_train,Y_train,cv=kfold,scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    message=\"%a: %f (%f)\" % (name,cv_results.mean(),cv_results.std())\n",
    "    print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure()\n",
    "fig.suptitle('Algorithm Comprasion')\n",
    "ax=fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tunning RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "for i in random_grid:\n",
    "    print(i,random_grid[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF = RandomForestRegressor()\n",
    "RF_random = RandomizedSearchCV(estimator = RF, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "RF_random.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_random.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'n_estimators': 800,\n",
    " 'min_samples_split': 5,\n",
    " 'min_samples_leaf': 2,\n",
    " 'max_features': 'auto',\n",
    " 'max_depth': None,\n",
    " 'bootstrap': True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models=[]\n",
    "models.append(('RF',RandomForestRegressor(\n",
    "                                random_state=seed\n",
    "                                n_estimators=800,\n",
    "                                max_features='auto',\n",
    "                                max_depth=None,\n",
    "                                min_samples_split=5,\n",
    "                                min_samples_leaf=2,\n",
    "                                bootstrap=True\n",
    ")))\n",
    "results=[]\n",
    "names=[]\n",
    "for name, model in models:\n",
    "    kfold=KFold(n_splits=num_folds,random_state=seed,shuffle=True)\n",
    "    cv_results=cross_val_score(model,X_train,Y_train,cv=kfold,scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    message=\"%a: %f (%f)\" % (name,cv_results.mean(),cv_results.std())\n",
    "    print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=RandomForestRegressor(\n",
    "n_estimators=800,\n",
    "max_features='auto',\n",
    "max_depth=None,\n",
    "min_samples_split=5,\n",
    "min_samples_leaf=2,\n",
    "bootstrap=True\n",
    ")\n",
    "results=[]\n",
    "model.fit(X=X_train,y=Y_train)\n",
    "predictions=model.predict(X_validation)\n",
    "print(mean_squared_error(Y_validation,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=StandardScaler().fit(X_train)\n",
    "rescaledX=scaler.transform(X_train)\n",
    "model=RandomForestRegressor(    random_state=seed,\n",
    "                                n_estimators=800,\n",
    "                                max_features='auto',\n",
    "                                max_depth=None,\n",
    "                                min_samples_split=5,\n",
    "                                min_samples_leaf=2,\n",
    "                                bootstrap=True\n",
    ")\n",
    "model.fit(rescaledX,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rescaledValidationX=scaler.transform(X_validation)\n",
    "predictions=model.predict(rescaledValidationX)\n",
    "print(mean_squared_error(Y_validation,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution={'Y_validation':Y_validation,'predictions':predictions}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sorted_solution=pd.DataFrame(solution).sort_values(by='Y_validation').reset_index(drop=True);sorted_solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lws = [6, 1]\n",
    "ax = sorted_solution.plot(legend=True,figsize=[20,20],color=['r','b'])\n",
    "for i, l in enumerate(ax.lines):\n",
    "    plt.setp(l, linewidth=lws[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The solution isn't perfect but its the best from tested algorithms"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
